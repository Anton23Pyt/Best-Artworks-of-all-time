from tensorflow.keras.preprocessing import image_dataset_from_directoryimport matplotlib.pyplot as pltimport numpy as npimport tensorflow as tffrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,BatchNormalizationimport cv2from tensorflow.keras import layersimport tensorflow as tfimport cv2from random import shufflefrom PIL import Imageimport tensorflow as tffrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictionsfrom tensorflow.keras.preprocessing import image as im# Helper librariesimport numpy as npimport matplotlib.pyplot as plimport randomdef shuffle_list(*ls):  l =list(zip(*ls))  shuffle(l)  return zip(*l)def delf(c,X_train,y_train):    x=[]    y=[]    for i in range(0,len(y_train)):        if y_train[i] in c:            x.append(X_train[i])            y.append(y_train[i])    x=np.asarray(x)    y=np.asarray (y)    return x,ytrain_dataset=image_dataset_from_directory('images',subset='training',validation_split=0.1,batch_size=7602,image_size=(150,150),seed=42)validation_dataset=image_dataset_from_directory('images',subset='validation',validation_split=0.1,batch_size=844,image_size=(150,150),seed=42)AUTOTUNE=tf.data.experimental.AUTOTUNEtrain_dataset=train_dataset.prefetch(buffer_size=AUTOTUNE)validation_dataset=validation_dataset.prefetch(buffer_size=AUTOTUNE)for image_batch, labels_batch in train_dataset:    X_train = image_batch.numpy()    y_train = labels_batch.numpy()k=0x=[]y=[]for i in range(0,len(X_train)):    X_train[i]=X_train[i]/255for i in range(0,len(X_train)):    out=cv2.rotate(X_train[i], cv2.ROTATE_90_COUNTERCLOCKWISE)    x.append(out)    y.append(y_train[i])    out1 = cv2.flip(out, -1)    x.append(out1)    y.append(y_train[i])    image = cv2.flip(X_train[i], -1)    image1 = cv2.flip(X_train[i], 0)    image2=cv2.flip(X_train[i], 1)    x.append(X_train[i])    x.append(image)    x.append(image1)    x.append(image2)    y.append(y_train[i])    y.append(y_train[i])    y.append(y_train[i])    y.append(y_train[i])x,y= shuffle_list(x,y)X_train=np.asarray (x)y_train=np.asarray (y)for image_batch, labels_batch in validation_dataset:    X_val = image_batch.numpy()    y_val = labels_batch.numpy()    breakfor i in range(0,len(X_val)):    X_val[i]=X_val[i]/ 255array=[]e=y_train.max()v=20fullarray1=[]fullarray2=[]for i in range(0,v):    fullarray1.append(X_train)    fullarray2.append(y_train)full=[]for i in range(0,len(fullarray1)):    model = Sequential()    model.add(Conv2D(16, (2, 2), padding='same', input_shape=(150, 150, 3), activation='relu'))    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Conv2D(32, (2, 2), padding='same', activation='relu'))    model.add(BatchNormalization())    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Conv2D(64, (2, 2), padding='same', activation='relu'))    model.add(BatchNormalization())    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Conv2D(128, (2, 2), padding='same', activation='relu'))    model.add(BatchNormalization())    model.add(MaxPooling2D(pool_size=(2, 2)))    model.add(Flatten())    model.add(Dense(256, activation='relu'))    model.add(Dropout(0.2))    model.add(Dense(128, activation='relu'))    model.add(Dropout(0.2))    model.add(Dense(50, activation='softmax'))    model.compile(loss='sparse_categorical_crossentropy', optimizer="adam", metrics=['accuracy'])    model.fit(fullarray1[i], fullarray2[i], epochs=10, verbose=2)    full.append(model)    print(i)anx=[]for i in range(0,len(full)):    Y_pred = full[i].predict(X_val)    anx.append(Y_pred)n=len(X_val)right=[]for i in range(0,n):    a=[]    for j in range(0,len(anx)):        a.append(max(anx[j][i]))    a.sort()    a2 = []    for j in range(0, len(a)):        if a[j] > 0.8:            a2.append(a[j])    if len(a2) == 0:        a2 = a[13:]    a = a2    g = a    print(a)    g2=[]    for j in range(0,len(g)):        for k in range(0, len(anx)):            if g[j] in anx[k][i]:                g2.append(k)                break    a=[]    for j in g2:        c=max(anx[j][i])        for k in range(0,len(anx[j][i])):            if anx[j][i][k]==c:                s=k                break        a.append(s)    print(a)    print(y_val[i])    a_set = set(a)    most_common = None    qty_most_common = 0    for item in a_set:        qty = a.count(item)        if qty > qty_most_common:            qty_most_common = qty            most_common = item    print(most_common)    print("===============")    right.append(most_common)f=0g=0for i in range(0,len(y_val)):    if right[i] == y_val[i]:        f = f + 1g=len(y_val)print(f/g)